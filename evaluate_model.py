# evaluate_model.py
import torch
from ultralytics import YOLO
from pathlib import Path
import cv2
import numpy as np
import matplotlib.pyplot as plt
import json


def evaluate_trained_model():
    """è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("æœè”¬è¯†åˆ«æ¨¡å‹è¯„ä¼°")
    print("=" * 50)

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model_paths = [
        'vegetable_fruit_final.pt',
        'runs/detect/vegetable_fruit_detection3/weights/best.pt',
        'runs/detect/vegetable_fruit_detection3/weights/last.pt'
    ]

    model_path = None
    for path in model_paths:
        if Path(path).exists():
            model_path = path
            break

    if not model_path:
        print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        return

    print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)

    # æ¨¡å‹ä¿¡æ¯
    print(f"æ¨¡å‹ç±»å‹: {type(model.model)}")

    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    print("\nğŸ“Š åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°...")
    try:
        results = model.val()
        print("éªŒè¯ç»“æœ:")
        print(f"  mAP50: {results.box.map50:.3f}")
        print(f"  mAP50-95: {results.box.map:.3f}")
        print(f"  ç²¾ç¡®åº¦: {results.box.mp:.3f}")
        print(f"  å¬å›ç‡: {results.box.mr:.3f}")
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {e}")

    return model


def test_single_images(model):
    """æµ‹è¯•å•å¼ å›¾åƒ"""
    print("\nğŸ–¼ï¸ å•å¼ å›¾åƒæµ‹è¯•")
    print("=" * 30)

    # æµ‹è¯•å›¾åƒè·¯å¾„
    test_paths = [
        "E:/data/train",  # ä»è®­ç»ƒæ•°æ®ä¸­éšæœºé€‰æ‹©
        "E:/data/test"  # å¦‚æœæœ‰æµ‹è¯•æ•°æ®
    ]

    test_images = []
    for test_path in test_paths:
        path = Path(test_path)
        if path.exists():
            # ä»æ¯ä¸ªç±»åˆ«éšæœºé€‰æ‹©ä¸€å¼ å›¾åƒ
            for class_folder in path.iterdir():
                if class_folder.is_dir():
                    images = list(class_folder.glob("*.jpg")) + list(class_folder.glob("*.png"))
                    if images:
                        test_images.append((images[0], class_folder.name))
                        if len(test_images) >= 10:  # é™åˆ¶æµ‹è¯•å›¾åƒæ•°é‡
                            break
            break

    if not test_images:
        print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•å›¾åƒ")
        return

    print(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾åƒ")

    # ç±»åˆ«åç§°
    class_names = [
        'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage',
        'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn',
        'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes',
        'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango',
        'onion', 'orange', 'paprika', 'pear', 'peas',
        'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans',
        'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip',
        'watermelon'
    ]

    results = []

    for i, (img_path, true_class) in enumerate(test_images):
        print(f"\næµ‹è¯• {i + 1}/{len(test_images)}: {img_path.name}")
        print(f"çœŸå®ç±»åˆ«: {true_class}")

        try:
            # é¢„æµ‹
            pred_results = model(str(img_path))

            if len(pred_results) > 0 and len(pred_results[0].boxes) > 0:
                # è·å–æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
                boxes = pred_results[0].boxes
                max_conf_idx = torch.argmax(boxes.conf)

                predicted_class_id = int(boxes.cls[max_conf_idx])
                confidence = float(boxes.conf[max_conf_idx])
                predicted_class = class_names[predicted_class_id] if predicted_class_id < len(
                    class_names) else "unknown"

                print(f"é¢„æµ‹ç±»åˆ«: {predicted_class}")
                print(f"ç½®ä¿¡åº¦: {confidence:.3f}")

                # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
                is_correct = predicted_class == true_class
                print(f"é¢„æµ‹ç»“æœ: {'âœ… æ­£ç¡®' if is_correct else 'âŒ é”™è¯¯'}")

                results.append({
                    'image': img_path.name,
                    'true_class': true_class,
                    'predicted_class': predicted_class,
                    'confidence': confidence,
                    'correct': is_correct
                })
            else:
                print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡")
                results.append({
                    'image': img_path.name,
                    'true_class': true_class,
                    'predicted_class': 'none',
                    'confidence': 0.0,
                    'correct': False
                })

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")

    # ç»Ÿè®¡ç»“æœ
    if results:
        correct_count = sum(1 for r in results if r['correct'])
        accuracy = correct_count / len(results)
        avg_confidence = np.mean([r['confidence'] for r in results if r['confidence'] > 0])

        print(f"\nğŸ“ˆ æµ‹è¯•ç»Ÿè®¡:")
        print(f"æ€»æµ‹è¯•å›¾åƒ: {len(results)}")
        print(f"æ­£ç¡®é¢„æµ‹: {correct_count}")
        print(f"å‡†ç¡®ç‡: {accuracy:.3f} ({accuracy * 100:.1f}%)")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")

        # ä¿å­˜ç»“æœ
        with open('test_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print("âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° test_results.json")


def create_inference_demo():
    """åˆ›å»ºæ¨ç†æ¼”ç¤ºè„šæœ¬"""
    demo_code = '''
# inference_demo.py
from ultralytics import YOLO
import cv2
from pathlib import Path

def predict_vegetable_fruit(image_path, model_path='vegetable_fruit_final.pt'):
    """é¢„æµ‹å•å¼ å›¾åƒçš„æœè”¬ç±»åˆ«"""

    # ç±»åˆ«åç§°
    class_names = [
        'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage',
        'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn',
        'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes',
        'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango',
        'onion', 'orange', 'paprika', 'pear', 'peas',
        'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans',
        'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip',
        'watermelon'
    ]

    # åŠ è½½æ¨¡å‹
    model = YOLO(model_path)

    # é¢„æµ‹
    results = model(image_path)

    # å¤„ç†ç»“æœ
    if len(results) > 0 and len(results[0].boxes) > 0:
        boxes = results[0].boxes

        # è·å–æ‰€æœ‰æ£€æµ‹ç»“æœ
        detections = []
        for i in range(len(boxes)):
            class_id = int(boxes.cls[i])
            confidence = float(boxes.conf[i])
            class_name = class_names[class_id] if class_id < len(class_names) else "unknown"

            detections.append({
                'class': class_name,
                'confidence': confidence,
                'box': boxes.xyxy[i].tolist()
            })

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        detections.sort(key=lambda x: x['confidence'], reverse=True)

        return detections
    else:
        return []

def visualize_prediction(image_path, model_path='vegetable_fruit_final.pt'):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""

    # é¢„æµ‹
    detections = predict_vegetable_fruit(image_path, model_path)

    # è¯»å–å›¾åƒ
    image = cv2.imread(str(image_path))
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # ç»˜åˆ¶æ£€æµ‹æ¡†
    for detection in detections:
        box = detection['box']
        class_name = detection['class']
        confidence = detection['confidence']

        # ç»˜åˆ¶çŸ©å½¢æ¡†
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # æ·»åŠ æ ‡ç­¾
        label = f"{class_name}: {confidence:.2f}"
        cv2.putText(image_rgb, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return image_rgb, detections

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    image_path = "test_image.jpg"  # æ›¿æ¢ä¸ºæ‚¨çš„å›¾åƒè·¯å¾„

    if Path(image_path).exists():
        detections = predict_vegetable_fruit(image_path)

        print("æ£€æµ‹ç»“æœ:")
        for i, det in enumerate(detections):
            print(f"{i+1}. {det['class']}: {det['confidence']:.3f}")
    else:
        print("è¯·æä¾›æœ‰æ•ˆçš„å›¾åƒè·¯å¾„")
'''

    with open('inference_demo.py', 'w', encoding='utf-8') as f:
        f.write(demo_code)

    print("âœ… æ¨ç†æ¼”ç¤ºè„šæœ¬å·²åˆ›å»º: inference_demo.py")


def main():
    """ä¸»å‡½æ•°"""
    print("æ¨¡å‹åç»­å¤„ç†é€‰é¡¹:")
    print("1. è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    print("2. æµ‹è¯•å•å¼ å›¾åƒ")
    print("3. åˆ›å»ºæ¨ç†æ¼”ç¤º")
    print("4. æ‰€æœ‰æ“ä½œ")

    choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()

    if choice in ['1', '4']:
        model = evaluate_trained_model()
    else:
        # åŠ è½½æ¨¡å‹ç”¨äºæµ‹è¯•
        model_path = 'vegetable_fruit_final.pt'
        if Path(model_path).exists():
            model = YOLO(model_path)
        else:
            print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
            return

    if choice in ['2', '4']:
        test_single_images(model)

    if choice in ['3', '4']:
        create_inference_demo()

    print("\nğŸ‰ æ“ä½œå®Œæˆï¼")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. è¿è¡Œ inference_demo.py æµ‹è¯•æ‚¨è‡ªå·±çš„å›¾åƒ")
    print("2. ä¼˜åŒ–æ¨¡å‹å‚æ•°é‡æ–°è®­ç»ƒ")
    print("3. æ”¶é›†æ›´å¤šæ•°æ®æ‰©å……æ•°æ®é›†")
    print("4. éƒ¨ç½²æ¨¡å‹åˆ°å®é™…åº”ç”¨ä¸­")


if __name__ == "__main__":
    main()